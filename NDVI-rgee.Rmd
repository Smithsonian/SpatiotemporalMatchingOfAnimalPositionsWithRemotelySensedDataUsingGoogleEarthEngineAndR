---
title: Extraction of spatio-temporal information from remotely sensed data using Google Earth Engine and R   
author: Ramiro D. Crego ^a,b^, Majaliwa M. Masolele ^c^, Grant Connette ^a,b^, and
  Jared A. Stabach ^a^
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: vignette
    math: mathjax
    toc: true
    toc_depth: 3
    collapsed: true
    smooth_scroll: true
    number_sections: true
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
---

a - Smithsonian National Zoo and Conservation Biology Institute, Conservation Ecology Center, 1500 Remount Rd, Front Royal, VA 22630, USA.
b - Working Land and Seascapes, Conservation Commons, Smithsonian Institution, Washington, DC 20013, USA
c - Boyd Orr Centre for Population and Ecosystem Health, Institute of Biodiversity, Animal Health & Comparative Medicine (IBAHCM), University of Glasgow, G12 8QQ, UK.

***

The following tutorial describes the code workflow presented in the manuscript "Enhancing animal movement analyses: Extraction of spatio-temporal information from remotely sensed data using Google Earth Engine and R." 

The code workflow allows you to find the closest image from an image collection to the time at which each GPS location was acquired and extract the pixel value. 

To use this code it is necessary to have a [Google Earth Engine](https://earthengine.google.com/) account and to install the `rgee` [package](https://r-spatial.github.io/rgee/#quick-start-users-guide-for-rgee).

## Laoding and preparing tracking data

The first step is to read a csv file with the telemetry data. 

For this example we randomly selected 100 GPS fixes from the entire wildebeest dataset used in the manuscript, obtained from [Movebank](https://www.datarepository.movebank.org/handle/10255/move.1098).
The data is provided in the repository within the folder Data.

```{r, message=FALSE}
library(sf)
library(dplyr)
trackingdata <- read.csv("./Data/Data.csv", header = T) #Load your dataset
head(trackingdata)
```

In the next step, we need to convert the dataframe into an sf object. We also need to set the date as a string with a ‘YYYY-MM-DDTHH:MM:SS’. We will use this data to convert it into milliseconds since midnight on January 1, 1970, a format used in Google Earth Engine to manage dates.

```{r}
trackingdata$Date <- as.POSIXct(trackingdata$timestamp, format = "%Y-%m-%d %H:%M:%S", tz="UTC") #Modify as necessary
trackingdata$Date <- as.factor(trackingdata$Date)
trackingdata$Date <- sub(" ", "T", trackingdata$Date) #Put in a format that can be read by javascript
trackingdata$ID <- seq(1:nrow(trackingdata)) # Add ID to each point (optional)
datasf <- st_as_sf(trackingdata, coords = c('location.long','location.lat'), crs = 4326) #Transform the dataframe into sf object. Make sure the name of the columns for the coordinates match. CRS needs to be in longlat WGS84.
head(datasf)
```


## Initialize rgee

```{r, echo=FALSE, message=FALSE, results='hide'}
library(rgee)
ee_Initialize()
```

Next, we need to load and initialize rgee.

```{r, eval=FALSE}
library(rgee)
ee_Initialize()
ee_check()
```

## Define Google Earth Engine functions

The next set of functions will be used to match images to the data and extract pixel values.

Note that you can edit the maximum temporal window allowed to find a match.

```{r}
#Function to add property with time in milliseconds
add_date<-function(feature) {
  date <- ee$Date(ee$String(feature$get("Date")))$millis()
  feature$set(list(date_millis=date))
}

#Join Image and Points based on a maxDifference Filter within a temporal window

#Set temporal window in days for filter. This will depend on the remote sensing data used.
tempwin <- 16 

#Set the filter
maxDiffFilter<-ee$Filter$maxDifference(
  difference=tempwin*24*60*60*1000, #days * hr * min * sec * milliseconds
  leftField= "date_millis", #Timestamp of the telemetry data
  rightField="system:time_start" #Image date
)

# Define the join. We implement the saveBest function for the join, which finds the image that best matches the filter (i.e., the image closest in time to the particular GPS fix location). 
saveBestJoin<-ee$Join$saveBest(
  matchKey="bestImage",
  measureKey="timeDiff"
)

#Function to add property with raster pixel value from the matched image
add_value<-function(feature){
  #Get the image selected by the join
  img1<-ee$Image(feature$get("bestImage"))$select(band)
  #Extract geometry from the feature
  point<-feature$geometry()
  #Get pixel value for each point at the desired spatial resolution (argument scale)
  pixel_value<-img1$sample(region=point, scale=250, tileScale = 16, dropNulls = F) 
  #Return the data containing pixel value and image date.
  feature$setMulti(list(PixelVal = pixel_value$first()$get(band), DateTimeImage = img1$get('system:index')))
}

# Function to remove image property from features
removeProperty<- function(feature) {
  #Get the properties of the data
  properties = feature$propertyNames()
  #Select all items except images
  selectProperties = properties$filter(ee$Filter$neq("item", "bestImage"))
  #Return selected features
  feature$select(selectProperties)
}
```

## Load image collection

In this example, we are using NDVI from MODIS Terra Vegetation Indexes 16-Day Global 250m data set. 
However, you can use any other remote sensing product of interest and filter to the desired dates.

One of the main advntages offered by Google Earth Engine is the enormous amount of data available to be used. The constantly growing database consists on more than a petabyte archive of publicly available remotely sensed imagery and other related data sets. In the study cases of the manuscript we used MOD13Q1 and ERA5_LAND/HOURLY, but data available includes other products from MODIS, data from other satellites such as Landsat, National Oceanographic and Atmospheric Administration Advanced Very High Resolution Radiometer (NOAA AVHRR), Sentinel 1, 2, 3 and 5-P, Advanced Land Observing Satellite (ALOS), and other products such as sea surface temperature data, CHIRPS climate data, topography data, and land cover data. The entire list of datasets is available at this [link](https://developers.google.com/earth-engine/datasets/catalog). 

Note that all image collections in Earth Engine have a code that you can extract from the link provided above and use to import into the workflow by modifying this example. 

We will set the start and end days to filter the image collections. Temporal availability depends on each dataset.

We will also create an object with the name of the band we are interested in working with. The name of the band is also specific to each image collection.

```{r}
start<-"2010-01-01"
end<-"2013-01-01"
imagecoll<-ee$ImageCollection('MODIS/006/MOD13Q1')$filterDate(start,end)
band <- "NDVI" #Name of the band to use. You can change to EVI for instance when using MOD13Q1.
```

## Extract pixel value 

A key function in this process is the `ee_as_sf` which converts the Google Earth Engine table in a sf object. This function provides three different options to convert the table (feature collection) into a sf object: 

1. getInfo: which is fast and direct but has a limit of 5000 features
2. drive: which exports data through your Google Drive account
2. gsc:  which exports data through your Google Cloud Storage account

You can find more information about this function in the help: ?ee_as_sf

We use here the `getInfo` option given it is direct and simple. However, this option has a limit of 5000 features to convert. For that reason, we are going to run a loop, processing 1000 features (points) per time to avoid errors. If memory limit errors are display, then you can reduce the number of points to extract each time by changing the `each` argument on the `rep` function.

In this example we only have 100 points so the loop will only run once, but for larger datasets the loop may run multiple times.

```{r}
datasf$uniq <- rep(1:1000, each=1000)[1:nrow(datasf)] #This is for up to 1 million points. To increase the max number of points, increase the value for max repetitions. To change the number of points to run per time, change the value in the argument each.

start_time <- Sys.time()
dataoutput <- data.frame()
for(x in unique(datasf$uniq)){
  data1 <- datasf %>% filter(uniq == x)
  # Send sf to GEE
  data <- sf_as_ee(data1)
  # Transform day into milliseconds
  data<-data$map(add_date)
  # Apply the join
  Data_match<-saveBestJoin$apply(data, imagecoll, maxDiffFilter)
  # Add pixel value to the data
  DataFinal<-Data_match$map(add_value)
  # Remove image property from the data
  DataFinal<-DataFinal$map(removeProperty)
  # Move GEE object into R
  temp<- ee_as_sf(DataFinal, via = 'getInfo')
  # Append
  dataoutput <- rbind(dataoutput, temp)
}
end_time <- Sys.time()
```

The time needed to run 100 points was:
```{r}
end_time - start_time
```

The new sf data frame with the pixel values in now stored as the `dataoutput` object. You can use this for further analysis.

```{r}
names(dataoutput)[4] <- band
dataoutput
```


## Visualize locations

```{r, message=FALSE}
Pres <- dataoutput
```


```{r, message=FALSE}
library(tmap)
tmap_mode('view')
tm_shape(Pres) + tm_dots(col = 'blue', title = "Presence")
```


